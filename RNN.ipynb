{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rnn.ipynb","provenance":[],"authorship_tag":"ABX9TyNRb/XqEKyNL2VXljOUWbDR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Jt-jyJ1OiucK","executionInfo":{"status":"ok","timestamp":1620386363790,"user_tz":-330,"elapsed":2032,"user":{"displayName":"Udara Vimukthi Lakshan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh27bhpBx9Zqb0AUKJ9kVUkZEeoZqiLbVJpw8CQkA=s64","userId":"05896419729734565722"}}},"source":["import copy, numpy as np\n","np.random.seed(0)\n","\n","# compute sigmoid nonlinearity\n","def sigmoid(x):\n","    output = 1/(1+np.exp(-x))\n","    return output"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"iVkRzw80jcgl","executionInfo":{"status":"ok","timestamp":1620386383365,"user_tz":-330,"elapsed":1302,"user":{"displayName":"Udara Vimukthi Lakshan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh27bhpBx9Zqb0AUKJ9kVUkZEeoZqiLbVJpw8CQkA=s64","userId":"05896419729734565722"}}},"source":["# convert output of sigmoid function to its derivative\n","def sigmoid_output_to_derivative(output):\n","    return output*(1-output)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"hl5HzSQ3jhAl","executionInfo":{"status":"ok","timestamp":1620386402020,"user_tz":-330,"elapsed":1050,"user":{"displayName":"Udara Vimukthi Lakshan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh27bhpBx9Zqb0AUKJ9kVUkZEeoZqiLbVJpw8CQkA=s64","userId":"05896419729734565722"}}},"source":["# training dataset generation\n","int2binary = {}\n","binary_dim = 8\n","\n","largest_number = pow(2,binary_dim)\n","binary = np.unpackbits(\n","    np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n","for i in range(largest_number):\n","    int2binary[i] = binary[i]"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"0wpCmjuejl0s","executionInfo":{"status":"ok","timestamp":1620386418592,"user_tz":-330,"elapsed":1320,"user":{"displayName":"Udara Vimukthi Lakshan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh27bhpBx9Zqb0AUKJ9kVUkZEeoZqiLbVJpw8CQkA=s64","userId":"05896419729734565722"}}},"source":["# input variables\n","alpha = 0.1\n","input_dim = 2\n","hidden_dim = 16\n","output_dim = 1"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"xPhGmricjpqd","executionInfo":{"status":"ok","timestamp":1620386438581,"user_tz":-330,"elapsed":1045,"user":{"displayName":"Udara Vimukthi Lakshan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh27bhpBx9Zqb0AUKJ9kVUkZEeoZqiLbVJpw8CQkA=s64","userId":"05896419729734565722"}}},"source":["# initialize neural network weights\n","synapse_0 = 2*np.random.random((input_dim,hidden_dim)) - 1\n","synapse_1 = 2*np.random.random((hidden_dim,output_dim)) - 1\n","synapse_h = 2*np.random.random((hidden_dim,hidden_dim)) - 1\n","\n","synapse_0_update = np.zeros_like(synapse_0)\n","synapse_1_update = np.zeros_like(synapse_1)\n","synapse_h_update = np.zeros_like(synapse_h)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"5_0IIl9xjufg","executionInfo":{"status":"ok","timestamp":1620387166328,"user_tz":-330,"elapsed":7932,"user":{"displayName":"Udara Vimukthi Lakshan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh27bhpBx9Zqb0AUKJ9kVUkZEeoZqiLbVJpw8CQkA=s64","userId":"05896419729734565722"}}},"source":["# training logic\n","for j in range(10000):\n","    \n","    # generate a simple addition problem (a + b = c)\n","    a_int = np.random.randint(largest_number/2) # int version\n","    a = int2binary[a_int] # binary encoding\n","\n","    b_int = np.random.randint(largest_number/2) # int version\n","    b = int2binary[b_int] # binary encoding\n","\n","    # true answer\n","    c_int = a_int + b_int\n","    c = int2binary[c_int]\n","    \n","    # where we'll store our best guess (binary encoded)\n","    d = np.zeros_like(c)\n","\n","    overallError = 0\n","    \n","    layer_2_deltas = list()\n","    layer_1_values = list()\n","    layer_1_values.append(np.zeros(hidden_dim))\n","    \n","    # moving along the positions in the binary encoding\n","    for position in range(binary_dim):\n","        \n","        # generate input and output\n","        X = np.array([[a[binary_dim - position - 1],b[binary_dim - position - 1]]])\n","        y = np.array([[c[binary_dim - position - 1]]]).T\n","\n","        # hidden layer (input ~+ prev_hidden)\n","        layer_1 = sigmoid(np.dot(X,synapse_0) + np.dot(layer_1_values[-1],synapse_h))\n","\n","        # output layer (new binary representation)\n","        layer_2 = sigmoid(np.dot(layer_1,synapse_1))\n","\n","        # did we miss?... if so, by how much?\n","        layer_2_error = y - layer_2\n","        layer_2_deltas.append((layer_2_error)*sigmoid_output_to_derivative(layer_2))\n","        overallError += np.abs(layer_2_error[0])\n","    \n","        # decode estimate so we can print it out\n","        d[binary_dim - position - 1] = np.round(layer_2[0][0])\n","        \n","        # store hidden layer so we can use it in the next timestep\n","        layer_1_values.append(copy.deepcopy(layer_1))\n","    \n","    future_layer_1_delta = np.zeros(hidden_dim)\n","    \n","    for position in range(binary_dim):\n","        \n","        X = np.array([[a[position],b[position]]])\n","        layer_1 = layer_1_values[-position-1]\n","        prev_layer_1 = layer_1_values[-position-2]\n","        \n","        # error at output layer\n","        layer_2_delta = layer_2_deltas[-position-1]\n","        # error at hidden layer\n","        layer_1_delta = (future_layer_1_delta.dot(synapse_h.T) + layer_2_delta.dot(synapse_1.T)) * sigmoid_output_to_derivative(layer_1)\n","\n","        # let's update all our weights so we can try again\n","        synapse_1_update += np.atleast_2d(layer_1).T.dot(layer_2_delta)\n","        synapse_h_update += np.atleast_2d(prev_layer_1).T.dot(layer_1_delta)\n","        synapse_0_update += X.T.dot(layer_1_delta)\n","        \n","        future_layer_1_delta = layer_1_delta\n","    \n","\n","    synapse_0 += synapse_0_update * alpha\n","    synapse_1 += synapse_1_update * alpha\n","    synapse_h += synapse_h_update * alpha    \n","\n","    synapse_0_update *= 0\n","    synapse_1_update *= 0\n","    synapse_h_update *= 0"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":133},"id":"x_n33V5BkEpT","executionInfo":{"status":"error","timestamp":1620387167386,"user_tz":-330,"elapsed":1048,"user":{"displayName":"Udara Vimukthi Lakshan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh27bhpBx9Zqb0AUKJ9kVUkZEeoZqiLbVJpw8CQkA=s64","userId":"05896419729734565722"}},"outputId":"cacbb9d7-aa3b-46d8-b911-7c2a6da97649"},"source":[" # print out progress\n","    if(j % 1000 == 0):\n","        print \"Error:\" + str(overallError)\n","        print \"Pred:\" + str(d)\n","        print \"True:\" + str(c)\n","        out = 0\n","        for index,x in enumerate(reversed(d)):\n","            out += x*pow(2,index)\n","        print str(a_int) + \" + \" + str(b_int) + \" = \" + str(out)\n","        print \"------------\""],"execution_count":11,"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-2b7e4b2397d3>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    if(j % 1000 == 0):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"]}]}]}